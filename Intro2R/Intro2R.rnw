\documentclass[12pt]{article}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={Introduction to R},    % title
    pdfauthor={Thomas J. Leeper},     % author
    pdfsubject={Political Science},   % subject of the document
    pdfkeywords={R}, 		% list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=false,       % false: boxed links; true: colored links
    pdfborder={0 0 0}
}
\usepackage{mdwlist}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{natbib}
\bibpunct{(}{)}{;}{a}{}{,} %set in-line reference punctuation
\usepackage{setspace}
\setlength{\bibsep}{0.1in} %set spacing between references
\setlength{\bibhang}{.5in} %set hanging indent for references
\setlength{\parindent}{0.5in}

\title{Really Introductory Introduction to R}
\author{Thomas J. Leeper\\
Department of Government\\
London School of Economics and Political Science}

\begin{document}

\maketitle


<<setup, echo=FALSE>>=
library("knitr")
opts_knit$set(progress = FALSE, verbose = FALSE, cache = TRUE, autodep = TRUE)
@

{\abstract The purpose of this document is to provide a brief introduction to R, focused on the core code needed to load and analyze social scientific data. While numerous other resources exist online to facilitate learning R and to provide guidance on performing particular procedures, this document serves as a quick-start guide catered to the needs of students who are learning R for the first time in the context of a course that provides little technical instruction in programming. My aim in this document is to make learning R relatively more smooth so that you focus more of your attention on learning statistics and political science research methods and less on being frustrated with the particular software we are using to implement those ideas.\footnote{Some of this material is adapted from Teppei Yamamoto's (2009) ``Introduction to R'' Short Course. It is released without copyright, but citation is always appreciated.}}

\section{Why R?}\label{sec:intro}
R refers to a statistical computing environment and the programming language used therein. We use R in this course because it is free, open source, well-documented, involves a large community of active users, and, most importantly, because it provides nearly unlimited functionality that far exceeds that of all other statistical packages.

The major drawback of using R is that it is difficult for new users to learn. If you have no background in programming, the learning curve can be very steep. Prior experience with statistical theory is often not terribly helpful for actually implementing that theory in R. Prior experience with other statistical packages (Stata, SAS, SPSS, Matlab) is somewhat helpful and several texts have been written to help users of those packages transition to R. If you have prior experience with programming in other languages, learning R will be relatively straightforward; BASIC, C\#, PHP, Python, Javascript, etc. all share certain similarities with R.

A second challenge is that not a lot of effort has been put into making R user-friendly for those with no programming experience. It is a command-based program. There is almost nothing to ``point-and-click'' anywhere in R. You need to learn to program in order to even use R. When you do something wrong in R, it will give you an error message. These errors are typically cryptic and unhelpful. Trial-and-error, use of the online help files, and use of Google will all be necessary. Your instructor and TA should not be your first resources for problems with R. There is a wealth of information on the internet about R and you should plan on using your classmates as resources for troubleshooting. I am here to help you when you have exhausted these other resources. \textbf{I expect you to spend at least 20 minutes trying to solve a problem and have thoroughly read the relevant help files before emailing me.}

So why use R if it is so difficult to learn and so different other statistical packages that are also widely used and with which you might already be familiar? The payoff of learning can be substantial. Because R is a programming language, it allows you an incredible amount of flexibility for the manipulation of data, the creation of unique functions for analyzing and describing those data, and unparalleled functionality for the tabular and graphical presentation of data. For these reasons, R can actually be fun, once you get to know it. Being competent in R will make learning other programming languages and other statistical packages much easier --- skills that may prove useful and/or necessary in your future careers. And, once you know how to program and do statistical analysis, people will think you're really intelligent even if you are not, which has its advantages on the job market.

So, let's get started with R.

\section{Getting Started}
The first step is downloading and installing R. This is straightforward and instructions can be found on the R homepage \url{https://www.r-project.org}. On that package click ``CRAN'' on the left-hand side to find an appropriate download for your operating system. R runs on all major operating systems in effectively the exact same fashion (yet another advantage of R!). Once you have R installed, you can open it and you'll be presented with a command line. This is where you tell R what you want to do. Because you don't know how to program any R code yet, try using R as a calculator. The standard mathematical operators all work, and follow the `order of operations.' Here are some simple examples: 
<<simplemath>>=
2+2
51-38
(2+4)*6
20/4
2^3
sqrt(4)
@

But, R is more than just a calculator (obviously!). To move away from using R as nothing more than a bloated calculator, we need to start doing some actual programming. But before we start writing more complex code, you'll probably want to move away from typing code directly into R and instead use another program to help you keep track of your code. There are a number of programs that can facilitate programming in R and dealing with its text and graphical outputs. First, you need a text editor to save the code you write. R doesn't automatically save the code that you tell it, so you'll save yourself a lot of time if you save all of your code in a separate program. You can use simple programs like Notepad, Wordpad, or even Word to do this, but better programs exist like Notepad++ (what I use), Emacs, Visual Studio, or RStudio.%\footnote{While I'd highly recommend you use a separate program to save your code, I cannot provide you any assistance with these other programs.}
\begin{itemize*}
\item Simple text editors: Notepad, TextPad, TextEdit, Wordpad (usually one or more of these is built-in with your computer's operating system)
\item Simple editor built in to R: \href{https://cran.r-project.org/web/packages/rite/index.html}{rite} (install and open with \texttt{install.packages("rite"); library("rite")}
\item Fancier text editors: \href{http://sciviews.org/Tinn-R/}{TINN-R}, \href{http://www.winedt.com/}{WinEdt}, \href{http://www.gnu.org/software/emacs/}{Emacs}, \href{http://aquamacs.org/}{Aquamacs}, \href{http://notepad-plus-plus.org/}{Notepad++}
\item Advanced front-ends for R: \href{http://rstudio.org/}{RStudio}, \href{http://www.revolutionanalytics.com/products/revolution-enterprise.php}{Revolution R}, \href{https://www.visualstudio.com/}{Visual Studio}
\item Graphical User Interface for R: \href{http://socserv.mcmaster.ca/jfox/Misc/Rcmdr/}{Rcmdr}
\end{itemize*}

If you save all of your code in one of these programs with a \texttt{.R} file extension, you should be able to completely reproduce your analysis simply by opening this file with R or copying and pasting the entirety of the code into R. This is helpful if you ask someone for help with your code because they can run all of your code and see where it may have had problems.

\subsection{Some General Notes Before Getting Started}

Some things to know about R and the R interpreter that you'll be interacting with:

\begin{itemize*}
\item R is basically a functional programming language with certain object-oriented capabilities. That means when we talk about particular statistics or procedures, we have to write code that tells R how to perform that statistical \emph{procedure} on a \emph{data object} and the function will generally return some new object. Usually, this looks something like \texttt{mean(x)}, where \texttt{mean()} is a procedure and \texttt{x} is an object (specifically, a vector of data points) and the result is a new object, which we can print to the console, save for later reuse, or simply abandon. When you first start working with R code, it can be hard to distinguish what text is a procedure from what text is the label for a data object, but over time this will get easier. If you use a text editor with syntax recognition, the text editor will highlight procedures (and sometimes objects) making the process of reading and writing code even easier.
\item R is case-sensitive. You need to type commands and variable names correctly or they will not work. As an example, \texttt{Mean()} does not mean \texttt{mean()}.
\item Arrow up and Arrow down on your keyboard cycle through previous commands you have entered. They do not scroll the screen up and down. Use your mouse scrollpad, Page Up and Page Down, or the scrollbar instead.
\item If you forget to put closing brackets on your commands, R will get confused and give you a \texttt{+} symbol instead of the usual \texttt{>} prompt. You can simply type the closing bracket in and the command will execute as if you typed it correctly the first time. This also means that R doesn't really recognize linebreaks. If you have a very long command (like for plots, which we'll talk about later), you may want to put the command on multiple lines so it is easier to read and R will have no problem with this, as long as you put the appropriate closing bracket at the end. If you use Mac OS or Linux OS, or some of the fancier text editors, closing brackets are often put in automatically as you type.
\end{itemize*}

\noindent Some general advice for when things eventually go wrong in R:

\begin{enumerate}
\item Don't panic!
\item Parsing errors versus syntax errors:
	\begin{itemize}
	\item Parsing errors mean you typed something wrong: \texttt{Error: unexpected ')' in "lm(y \textasciitilde)"}
	\item Syntax errors mean you typed correctly but R didn't understand: \texttt{Error in eval(expr, envir, enclos) : object 'y' not found}
	\end{itemize}
\item Google the error or warning
\item Use \href{http://stackoverflow.com/questions/tagged/r}{StackOverflow} to get help
\end{enumerate}



\subsection{Creating simple constants and vectors}
To do statistical analysis, we need to have data. R has various objects for storing different types of data. The simplest way to store data is in a \emph{constant}. A constant, to R, is just a number that is given a name. We use the \texttt{<-} to store something into a particular labeled object; we can also use \texttt{=} to do this; or \texttt{->} by reversing the argument:
<<constant>>=
a<-4
a <- 4
# 4->a # this works, too
a
@
Here, we've created a constant called \texttt{a}, which has the value 4. R doesn't automatically display the value of \texttt{a} when we assign a value to it. To see the value of \texttt{a}, you need to simply type \texttt{a} and hit \texttt{<enter>}. We can store multiple constants, give new values to a constant we've already defined, and then conduct mathematical operations on those constants:
<<constants>>=
a <- 4
a <- 6
a
b <- 3
b+2
b*a
@
Note that $b*a=18$ in the code above, even though we calculated \texttt{b+2} in the line directly above that calculation. You have to store a result as a constant to be able to use that result later.

Storing all of our data as individual constants, isn't very efficient, though. Let's say we want to collect a piece of data for a number of units (e.g., people in this class). We can store a set of data points as a \emph{vector} in R using the \texttt{c()} command. Vectors can have any length and we can perform mathematical operations on vectors.

<<vector>>=
a <- c(1,2,3,4,5,6,7,8,9,10)
a
a*2
b <- a
b
@

You can also create a sequence of numbers using \texttt{seq()} or just the \texttt{:}.
<<vector1.5>>=
a <- seq(1:10)
a
b <- 1:10
b
@

This is especially helpful if we want to calculate any basic statistics on a particular vector of data (what we might, in social science language, call a variable). Let's imagine for instance that we collect a number of 2-dice rolls and record the sum in a vector called dice. We can then find out a number of pieces of information about this set of rolls.

<<vector2>>=
dice <- c(2,2,3,4,4,5,5,5,5,5,6,6,7,7,7,7,8,9,10,11)
table(dice) #a simple tabulation of how many of each value are in the vector
fivenum(dice) # the five number summary (min, Q1, median, Q3, max)
quantile(dice, c(0.1,0.2,0.6,0.8)) # arbitrary quantiles
summary(dice) # a set of basic univariate statistics for the vector
@

Note we can also obtain these summary values individually.
<<vector3>>=
dice <- c(2,2,3,4,4,5,5,5,5,5,6,6,7,7,7,7,8,9,10,11)
length(dice) #how many observations are there?
min(dice) #minimum
median(dice) #median
max(dice) #maximum
max(dice)-min(dice) #range
sum(dice)
sum(dice)/length(dice)
mean(dice) #mean
v <- var(dice) #variance
v
sqrt(v) #standard deviation
sd(dice) #easier way of getting standard deviation
@

One thing that can be initially confusing for new users of R is exactly what is happening when you type in a given command. R does not solve mathematical equations. Instead, like any programming language, it performs a set of procedures in a specific order on a particular data object (i.e., it performs an algorithm). What does an algorithm look like and why does it matter? To use R effectively, one needs to understand what it is doing and how to think in algorithms rather than equations. Think about the formula for the mean of a set of data (like our dice roll data). The mathematical equation is $\bar{x}=\Sigma x_{i} / n$. This translates into an R algorithm like the following:
<<algorithm>>=
dice <- c(2,2,3,4,4,5,5,5,5,5,6,6,7,7,7,7,8,9,10,11)
s <- 2+2+3+4+4+5+5+5+5+5+6+6+7+7+7+7+8+9+10+11
s
len <- length(dice)
len
m <- s/len
m
@

As we can see, the result is the same as using R's built-in \texttt{mean()} function. We could attempt something similar by converting the equation for variance ($Var[x]=\Sigma (x_{i} - \bar{x})^2 / (n-1)$) into an algorithm (the first four steps of which are the same as calculating the mean):
\begin{enumerate*}
\item Load the vector of all $x_i$, called \emph{data}
\item Sum all $x_i$, store this result as \emph{sum}
\item Count the number of $x_i$, store this as \emph{length}
\item Divide \emph{sum} by \emph{length}, store this as \emph{mean}
\item Create a new vector, where each entry in the vector is the difference between each $x_i$ in \emph{data} and mean of all $x_i$ (\emph{mean}),  store as \emph{deviations}
\item Create a new vector, where each entry is the square of the entry in \emph{deviations}, store as \emph{squares}
\item Sum all values in \emph{squares}, store as \emph{sumsquares}
\item Divide \emph{sumsquares} by one less than \emph{length}, store as \emph{variance}
\end{enumerate*}
We can then write that algorithm in R:
<<algorithm2>>=
dice <- c(2,2,3,4,4,5,5,5,5,5,6,6,7,7,7,7,8,9,10,11)
s <- sum(dice)
len <- length(dice)
m <- s/len
deviations <- dice-m
squares <- deviations^2
sumsquares <- sum(squares)
v <- sumsquares/(len-1)
v
sqrt(v)
@

As we can see, our mathematical equation for variance is easily converted to an algorithm that we can then write in R code. While the \texttt{var()} command is short and simple, it reflects all of this underlying code. While we can rely on these built-in functions, it is important to keep in mind what is happening behind the scenes. Thinking like a computer programmer rather than a math student will greatly facilitate your transition to R.

Two additional important tips here. First, you can use the \texttt{round()} command to round a given value to a specified number of decimal places. Second, you can nest commands inside of one another rather than produce a constant that you'll only use one time (e.g., to calculate the standard deviation we can create a constant that stores the variance and take the square root thereof OR we can simply take the square root of the variance directly).
<<vector3.5>>=
<<vector3,echo=FALSE>>
round(mean(dice),2)
round(sqrt(var(dice)),2)
@

We can also extract one or more observations from a vector. For instance, if we wanted to know the value of the 1st through 3rd rolls, or just the value of the 7th roll:
<<vector4>>=
dice <- c(2,2,3,4,4,5,5,5,5,5,6,6,7,7,7,7,8,9,10,11)
dice[1:3]
dice[7]
@
We'll discuss more about extracting particular observations in a moment. Clearly, though, conducting simple analyses in R is pretty straightfoward. Most of the commands are semantic --- that is, the command to obtain a particular statistic is intuitive. This is generally the case, but can get confusing once we move into more advanced statistics. Using comments in your R programming will therefore be vital to you and I both understanding what you're trying to do with a given piece of code. The pound sign (\#) can be used to create comments in the code, which can be helpful when you have to do complex things in your code and you want to remind yourself (or me) what you're trying to do with each bit of code. They can be included at the end of a line of code or simply on their own. Just start the line with a pound sign and then continue with code on the next line.

Now let's work with two variables. Let's try comparing two sets of dice rolls, by looking at their means, variances, and the correlation between the two sets of rolls.
<<matrices1>>=
dice1 <- c(7,7,4,5,3,6,8,2,12,10)
dice2 <- c(8,4,7,7,7,7,6,6,3,4)
mean(dice1)
sd(dice1)
mean(dice2)
sd(dice2)
cor(dice1,dice2)
@

\subsection{Creating matrices and data.frames}

We could also represent these data a different way. Rather than having two vectors, we could ``column bind'' them (using the \texttt{cbind()} command) into a \emph{matrix}, which we can also call whatever we want.
<<matrices2>>=
dice1 <- c(7,7,4,5,3,6,8,2,12,10)
dice2 <- c(8,4,7,7,7,7,6,6,3,4)
dice <- c(dice1,dice2)
set <- c(1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2)
dice.mat <- cbind(set,dice)
dice.mat
@

We can also use the corresponding \texttt{rbind()} to ``row bind'' two or more vectors, which has the same effect as \texttt{cbind()}, but treats each vector as a row/observation. The \texttt{t()} command transposes a matrix. If we apply this function to our original matrix (that we constructed using \texttt{cbind()}), we will obtain the second matrix we constructed (using \texttt{rbind()}).
<<rbind>>=
<<matrices2,echo=FALSE>>
rbind(set,dice)
t(dice.mat)
@

Here, we created our vectors from above, but then combined them into a single vector using the \texttt{c()} command. We then created a separate vector called \texttt{set} into which we stored the identifier for whether the observation came from our first or second set of rolls. We then bound these two vectors together into a matrix called \texttt{dice.mat}, which has dimensions 20 x 2. Now this is starting to look like a traditional rectangular dataset where each observation is represented as a row and each variable is a column. We can look at the dimensions of the new matrix, including its number of columns and number of rows and use that information to extract particular values (or sets of values) from the matrix. We can extract a particular observation (e.g., observation 5), a particular variable (e.g., the second variable), or the observation for a given variable (e.g., the value of the roll for our fifth roll) just as we did with vectors, but now our syntax reflects that row and column position, as follows:
<<matrices3>>=
<<matrices2,echo=FALSE>>
ncol(dice.mat)
nrow(dice.mat)
dim(dice.mat) #obtain both dimensions
dice.mat[5,]
dice.mat[,2]
dice.mat[5,2]
@

We could continue to bind vectors to this matrix. For example, we could bind a vector to the matrix that identifies the color the dice we rolled. Here we'll be dealing with a vector of \emph{strings}, which we cannot perform statistical or mathematical operations, but that we often find in real world data.
<<matrices4>>=
<<matrices3,echo=FALSE>>
color <- c("red","red","blue","yellow","blue","red","red",
        "blue","yellow","blue","red","red","blue","yellow",
        "blue","red","red","blue","yellow","blue")
dice.mat2 <- cbind(dice.mat,color)
dice.mat2
@

We can also transform this matrix into a different type of R object called a \emph{data.frame}. Matrices and data.frames have some similar properties, but also differences that you will learn over the course of this course. Importantly, most data that we read in from an outside file (as opposed to typing in ourselves) will be in the form of a data.frame. But, we can also transform our matrix into a data.frame. If you want to know whether something is a matrix or a data.frame, you can also test it using an \texttt{is.matrix()} or \texttt{is.data.frame()} command.
<<data.frame>>=
<<matrices4,echo=FALSE>>
data.frame <- as.data.frame(dice.mat2)
is.data.frame(data.frame)
is.matrix(data.frame)
is.data.frame(dice.mat2)
is.matrix(dice.mat2)
@

One of the key advantages of data.frames is that we can refer to columns of the data.frame by their variable names, as opposed to their position number (as we have to do with matrices). We can find these names using the \texttt{names()} command and isolate a particular column of the matrix by using the dollar sign operator. Note that this produces the same result as using the brackets to identify the particular column (as we did above with our matrix).
<<data.frame2>>=
<<data.frame,echo=FALSE>>
names(data.frame)
data.frame$color
data.frame[,3]
@

We can also extract a column or row from a data.frame and turn it into a vector. We might want to do this if we plan on transforming the data in some way and saving that transformed data for later use. We could also add that new vector back into the data.frame under a new name. The vector and column in the data.frame will have the same properties, but changing one has no effect on the other. This aspect can sometimes get confusing, especially once you start working with data that contains many variables. You can have a column in a data.frame and a separate vector that have the same name. To work with the vector simply use the name, to use the column in the data.frame, you have to use the \texttt{\$} operator.
<<data.frame3>>=
<<matrices4,echo=FALSE>>
df <- as.data.frame(dice.mat)
df$dice
half <- df$dice+1
df$half <- half
summary(half)
summary(df$half)
half <- half+1
summary(half)
summary(df$half)
@

Be careful here, because you can also accidentally change a vector by giving something else the same name. For example, we can eliminate the vector entirely by assigning a constant value to it or by giving it the missing value code \texttt{NA}.
<<data.frame4>>=
<<data.frame3,echo=FALSE>>
half
half <- 1
half
half <- NA
half
@

We can apply the same \texttt{summary()} and \texttt{table()} commands that we used on vectors to matrices and data.frames. We can also use \texttt{table()} on two variables to construct crosstabs.
<<twowaytable>>=
<<data.frame3,echo=FALSE>>
summary(df)
table(df$dice,df$set) #crosstab
with(df,table(dice,set)) #an alternative method for getting crosstabs
prop.table(table(df$dice,df$set)) #convert cell counts to proportions
@

Sometimes you want to know all the objects you have created. To see these, use the \texttt{ls()} command.
<<objects>>=
ls()
@
You can also use \texttt{rm(list=ls(all=TRUE))} to clear all objects; this effectively starts a new R instance because you will lose all of your work.

\subsection{R Output}
Just as it is helpful to save your R code in an outside file, it is also sometimes helpful to send the output of R to an outside file so that you can retrieve it later. R provides the \texttt{sink()} command to allow you to put all of the output it produces into an outside .txt file in addition to (or instead of) sending the output to the R console. This can be helpful when you start performing a large number of analyses. (You need to enter the \texttt{sink()} command, complete with all its arguments before conducting your analyses.)

\section{R's Built-in Datasets}\label{sec:datasets}
One nice feature of R is that it comes with several built-in datasets, which allow you to quickly play around with R and different functionality. You can see a list of datasets that are available by typing \texttt{data()} on the console. A list of installed datasets will be available. Those that are listed can be accessed just by referring to the dataset name.

Some commonly used datasets are \texttt{iris} and \texttt{mtcars}:

<<>>=
head(iris) # see first few observations in iris

str(mtcars) # see the contents of mtcars
@



\section{Working with Real Data}\label{sec:data}
Now that we've worked with some of the basic manipulations of data and the type of objects that R understands (constants, vectors, matrices, and data.frames), we can proceed forward by working with actual data. It is rare that we'll have to enter our own data manually into R. Instead, we'll likely have to import it from an outside file of various types. To this, we have to start by telling R where to find the data. You can either do this visually by selecting \texttt{File > change dir}, or you can use the \texttt{setwd()} command.\footnote{The file path you use will depend on your operating system and the folder where you have saved the data file on your computer. See the R help files for how to do this. You can access the help file by typing \textbf{? setwd()} into R. You can use that question mark syntax to get help on any R command.} This sets the working directory for your current R session. You can change it later as needed, but you'll need to set it each time you work with R.

<<setwd,eval=FALSE>>=
setwd("C:/Users/Thomas/Documents/Dropbox/Courses/")
@

You can check what your working directory is by using the corresponding \textbf{getwd()} command.

After your working directory is set, you can read data into R. How you do this will depend on the type of data file you are working with, but we'll use a convenient package called ``rio'' to do our data importing. R has a bunch of different data import functions depending on which type of data you are using. rio has a function called \texttt{import()} that figures out what kind of data you have and reads it in as appropriate. To use rio, you'll need to install the package.

\subsection{Packages}
Installing packages is straightforward. You can do this in many ways, but the easiest is from within R. Type \texttt{install.packages("rio")} to install the rio package. R will then search the CRAN website (\url{https://cran.r-project.org}) for the package and install it. You may be prompted to specify a ``repository mirror'' from which to download the package. It really doesn't matter which one you choose.

On Windows, you may need to run R ``as an administrator'' in order for the package to download and install correctly.

To actually use a package (once it is installed on your computer, using the above instructions), you can call the package using the \texttt{library()} command in R.

<<foreign>>=
library("rio")
@

The package is now ready to use. Now, let's try reading in some data.

\subsection{Reading in (and Writing Out) Data}
Here's an example dataset that includes six variables describing four patients who entered a hospital for treatment.

\begin{quote}
patient,dob,entry,discharge,fee,sex\\
001,10/21/1946,12/12/2004,12/14/2004,8000,1\\
002,05/01/1980,07/08/2004,08/08/2004,12000,2\\
003,01/01/1960,01/01/2004,01/04/2004,9000,2\\
004,06/23/1998,11/11/2004,12/25/2004,15123,1\\
\end{quote}

We can read this data into R from an outside ``patient.csv'' file and display the resulting data.frame.

<<readdata>>=
<<setwd,echo=FALSE>>
library("rio")
u <- "https://raw.githubusercontent.com/leeper/Rcourse/gh-pages/Data/patient.csv"
d  <-  import(u)
dim(d)
d
@

Note that this creates a data.frame called \textbf{d} that has a row for each patient and a column for each variable.\footnote{You can call your data anything, but you need to store it as something. I always call my data.frames \textbf{data} or some variant thereof for simplicity, but you can use anything you want.} You can now proceed with analysis on this data.frame as you would any other, just as we did with the data.frames we created above.

When we have created a data.frame (and potentially manipulated it in a number of ways) and want to save our new creation, we can use the \texttt{export(data, "data.csv")} command to store the data.frame as a .csv file in our working directory.

\subsection{Data Manipulation and Subsetting}
Often, we want to work with some smaller part of a dataset rather than the entire dataset --- for example, we may only be interested in looking at a subset of observations or looking only at some variables. R has a number of functions for manipulating and subsetting data.frames that can help us with these tasks. Recall that for data.frames, we can use the \texttt{\$} symbol to identify specific variables or use the \texttt{[,]} brackets to index specific observations, specific variables, or both. We will also make use of the \texttt{!} symbol and the \texttt{-} symbol, which serve as ``not'' commands. We'll use the patient data we just read in to demonstrate the results of using these commands in various combinations.

<<subset1>>=
<<readdata,echo=false>>
d$patient
d[,1]
d[, "patient"]
d[1,]
d[d$patient == 001,]
d[d$sex == 2,]
d[d$sex != 1,]
d[d$sex == 2, "dob"]
@

\noindent Note: If you want to further use a subset of a data.frame, it is necessary to store that subset (of observations and/or variables) as a new object:

<<subset2>>=
<<readdata,echo=false>>
data_females  <-  d[d$sex==2,]
@

It is also possible to temporarily use a subset of data using the \texttt{with()} command:

<<subset3>>=
<<readdata,echo=false>>
with(d, mean(fee))
with(d[d$sex==1,], mean(fee))
with(d[d$sex==1,], mean(fee))
@

\noindent Note that here, you don't need to use the \texttt{\$} operator or \texttt{[,]} indexing brackets because the \texttt{with()} command tells R which data.frame to use when we call the \texttt{fee} variable.

We can also achieve the above several other ways using other R functions. The \texttt{aggregate()} function is particularly helpful when we want to extract a statistic for different subsets of a dataset:

<<subset4>>=
<<readdata,echo=false>>
aggregate(fee ~ sex, data = d, FUN = mean)
@


\subsubsection{Missing Data}
Missing data, represented in R using \texttt{NA}, will inevitably create problems for you at some point during this course. Whereas some statistical packages, like SPSS, SAS, and Stata, will automatically drop missing values from many types of analysis (leaving the original data.frame or matrix intact), R will often choke when you have missing values. This typically causes confusing errors about the length of vectors or dimensions of matrices. It is also good statistical practice to be fully aware of the amount and locations of missing data in your dataset because the standard practice of dropping observations with missing values can often create worse inferential problems (like selection bias, misleading results, etc.) than using a number of other strategies for addressing missing data.

Perhaps most confusing is that mathematical operations involving missing values all produce missing values, even if you might expect them to treat the \texttt{NA} as a 0:

<<na1>>=
missing <- NA
value1 <- 2
value2 <- 3
value1+value2+missing
@

Something similar happens with vectors, matrices, and data.frames. Take, for instance, a vector (\texttt{v1}) and let's remove two values and see the effect on various functions:

<<na2>>=
v1 <- c(1,2,3,4,5,6,7,8,9,10)
length(v1)
sum(v1)
mean(v1)
v2 <- c(1,2,3,4,NA,6,7,8,9,NA)
length(v2)
sum(v2)
mean(v2)
@

You can also identify which values in a vector, matrix, or data.frame are missing using the logical function \texttt{is.na()}. You can also nest this command inside other commands. The resulting vector of \texttt{TRUE} and \texttt{FALSE} logicals can also be treated mathematically, such as using \texttt{sum()} to count the number of missing values in the vector.

<<na3>>=

<<na2,echo=false>>
is.na(v2)
sum(is.na(v2))
@

We could simply remove the missing values for the purposes of performing the calculation. For most functions, this can be accomplished by adding a \texttt{na.rm=TRUE} argument within the function. Or, we could create a subset of the original data that omits the missing values using the \texttt{na.omit()} function.

<<na4>>=

<<na3,echo=false>>
v3 <- na.omit(v2)
length(v3)
sum(v3)
mean(v3)
@

Using the \texttt{na.omit()} function changes the length of the original vector. So, while \texttt{cor(v1,v2)} will give us a resulting correlation between our original two vectors of \texttt{NA}, if we attempt to calculate the correlations of \texttt{cor(v1,v3)} or \texttt{cor(v2,v3)} R will produce an \texttt{incompatible dimensions} error because \texttt{v3} has a length of 8, while both \texttt{v1} and \texttt{v2} have length 10. In practice, you may want to consider imputing missing values rather than simply removing missing values to avoid these technical errors and larger inferential problems. That, however, is the subject for another discussion.

\section{Randomness}\label{sec:random}

One of the very convenient sets of functionality in R is its ability to generate (pseudo-)random numbers and to conduct sampling. Details about the different random number generates can be found here: \url{http://stat.ethz.ch/R-manual/R-devel/library/stats/html/Distributions.html}. Random numbers can be generated according to a number of different distributions including (using the attendant command):
\begin{itemize*}
\item Normal/Gaussian: \texttt{rnorm()}
\item Chi-squared: \texttt{rchisq()}
\item Student's t: \texttt{rt()}
\item Uniform: \texttt{runif()}
\end{itemize*}

Each of these (and the other) distributions also have built-in functions for producing density functions, quantiles, and p-values using commands of the form \texttt{dnorm()}, \texttt{qnorm()}, and \texttt{pnorm()}, respectively. True random numbers and sequences can also be obtained using the \texttt{random} package, which makes calls to the random number generates at \url{http://www.random.org} instead of the built-in R pseudo-random number generators. Random integers can be extracted using the \texttt{random} package or by rounding the output of one of the \texttt{runif()}-type functions.

Besides generating random numbers, R also provides the ability to sample values from a vector or observations from a data.frame using the \texttt{sample()} command. Sampling can be conducted with or without replacement and involve samples of any size:

<<random>>=
set.seed(1)
set  <-  c(1,2,3,4,5)
sample(set,5,replace=FALSE)
sample(set,5,replace=TRUE)
sample(set,10,replace=TRUE)
@

The \texttt{set.seed(1)} function makes our result reproducible by setting the ``seed'' of the pseudo-random number generator so that we can get the same result each time we run this code. Sampling commands could be used to conduct simulations, including bootstrapping and permutation procedures, as well as Monte Carlo simulations (the latter, in combination with the random number generation functions).

\section{Plots}\label{sec:plots}
The real power of R is its sophisticated graphical functionality. R comes with a number of built-in plotting commands; other plots can be produced using a variety of packages or by writing your own code. 

We'll use an add-on package called ``ggplot2'' to do graphing because it provides a very flexible interface for drawing lots of different types of plots. We'll need to install it: \texttt{install.packages("ggplot2")} before we can use it to draw a graph. As with any package, we then need to load the package to use it:

<<loadggplot2>>=
library("ggplot2")
@


We'll use one of R's built-in datasets to produce some interesting plots. The most important function in ggplot2 is \texttt{ggplot()}, which is what sets up a data.frame to let us plot it. We can then add different plot elements using \texttt{+} operator to control what is displayed and how the plot looks. A cheatsheet for ggplot2 is available here: \url{https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf}. 

Basically, a ggplot2 plot is a dataset, plus some information about what variables you want to plot, plus information about how you want to plot those variables. To obtain a histogram, which is a graphical representation of the distribution of a variable, we just do:

<<fig.width = 4, fig.height = 4>>=
ggplot(iris) + aes(x = Sepal.Length) + geom_histogram(binwidth = .25)
@

The above code indicates that we are using the \texttt{iris} dataset that is built in to R, we want to graph the \texttt{Sepal.Length} variable from those data, and we want a histogram so we use the \texttt{geom\_histogram}. When we want a different kind of graph of the same data, we just change the geom:

<<fig.width = 4, fig.height = 4>>=
ggplot(iris) + aes(x = Sepal.Length) + geom_density()
@

There are many, many geoms for single-variable plots (see the cheatsheet) and many, many more for two or more variable situations. Here's an example of a two-variable plot in ggplot2:

<<fig.width = 4, fig.height = 4>>=
ggplot(iris) + aes(x = Sepal.Length, y = Sepal.Width) + geom_point()
@

The neat feature of ggplot2 is that we can \textit{layer} multiple graphical elements on top of one another. So, in the above graph, we can easily add a smoothed line showing the relationship between the two variables more clearly:


<<fig.width = 4, fig.height = 4>>=
ggplot(iris) + aes(x = Sepal.Length, y = Sepal.Width) + geom_point() + geom_smooth()
@


To display categorical data, we would use different geoms. Here we display boxplots showing the distribution of \texttt{Sepal.Length} across the different species in the \texttt{iris} dataset:

<<fig.width = 4, fig.height = 4>>=
ggplot(iris) + aes(x = Species, y = Sepal.Length) + geom_boxplot()
@



\subsection{Saving Plots}
Once you have created a plot, you will likely want to save it outside of R (for example, to include in a problem set). The easiest way to do this is by writing a \texttt{ggsave()} line into your code:

\begin{verbatim}
ggplot(iris) + aes(x = Species, y = Sepal.Length) + geom_boxplot()
ggsave("myplot.png")
\end{verbatim}

\noindent This saves your plot as a PNG file in your working directory.

\section{Basic Programming Tools: Logics, etc.}\label{sec:programming}
As I've stated above, R is a programming language. Thus, it will be helpful to understand some basic programming to help you move beyond the relatively simple tasks we've learned about so far. I will focus on four areas:
\begin{enumerate*}
\item Logicals
\item Functions
\item Apply
\item Loops
\end{enumerate*}

\subsection{Logicals}
Logicals allow you to test the equivalence of different R objects in any typical mathematical fashion:
\begin{itemize*}
\item Equal to: \texttt{==} \footnote{Note the double-plus (==), not to be confused with the single-plus (=), which is used to store a value.}
\item Greater than: \texttt{>}
\item Less than: \texttt{<}
\item Greater than or equal to: \texttt{>=}
\item Less than or equal to: \texttt{<=}
\item Not: \texttt{!}
\end{itemize*}
So, we can use these to produce \texttt{TRUE} or \texttt{FALSE} results from R, which is helpful when building complex programs. Generally it is not terribly helpful to test a simple logical like \texttt{2>1}, so instead these logical statements are often used as conditions for performing further operations inside an \texttt{if()} statement.

\subsubsection{IF-THEN, ELSE}
Logicals on their own, are not that helpful. Rather, they are helpful for building complex programs with subroutines that are only run under particular conditions. We could, for instance, set the value of one variable depending on the value of another, or only conduct an operation on an object if it is non-missing. While some programming languages require you to type ``then'' in order to actually execute the second part of an if-statement, R does not require this. Take a look at the following simple examples:

<<if1>>=
x <- 2
if (x==1) q <- "FAIL"
if (x==2) q <- "SUCCESS"
q
if (is.na(x)) q <- "FAIL"
if (!is.na(x)) q <- "SUCCESS"
q
@

These logicals can also be combined with the AND \texttt{\&} or OR \texttt{\}} operators to produce logicals that meet more than one criterion.

<<if2>>=
x <- 2
q <- NA
if (!is.na(x) & x>2) q <- "SUCCESS"
q
if (!is.na(x) | x>2) q <- "SUCCESS"
q
@
Here we can see \texttt{q} is not set to equal \texttt{SUCCESS} under the first statement because while x is non-missing, x is not greater than 2. Under the second statement, however, where we use the OR operator \texttt{q} is set to \texttt{SUCCCESS} because x is non-missing, so it does not matter what the value of x is --- only one of the two logicals in parentheses needs to be true.

While we can string an infinitely long string of \texttt{if()} statements in a row, sometimes we do not need R to evaluate all of the statements --- for example, we may want to stop evaluating the \texttt{if()} statements once one of them is satisfied. We can use the \texttt{else if ()} and \texttt{else} commands in these instances.

<<if3>>=
a <- 4
if (a==1) x="Stopped at 1" else
if (a==2) x="Stopped at 2" else
if (a==3) x="Stopped at 3" else
if (a==4) x="Stopped at 4" else
if (a==5) x="Stopped at 5" else
if (a==6) x="Stopped at 6 or larger"
x
@
You can see here that even though we had two lines of code after the:
\begin{verbatim}
if (a==4) x <- "Stopped at 4" else
\end{verbatim}
command, those lines were not evaluated because \texttt{a} was set to 4. Thus, we don't have to spend computing time and power to produce a logical \texttt{TRUE} or \texttt{FALSE} for each if-statement, only for the relevant if-statement.

\subsection{Functions}
While R and its supplemental packages provide an enormous amount of functionality, you sometimes feel compelled to write additional functionality to serve a particular need. In this case, you'll need to use the \texttt{function()} command. Let's say, for instance, that we had calculated daily high temperatures for a week in Fahrenheit, but needed them in Celsius. We could perform the conversion manually on each score:

<<temp1>>=
temp1.f <- 65
temp1.c <- ((65-35)*5)/9
temp1.c
@

Or we write a function to conduct the conversion without having to retype the math for each score:

<<temp2>>=
temps <- c(65,68,72,76,69,78,68)
ftoc <- function(f) {
	c <- ((f-35)*5)/9
	print(c)
}
ftoc(temps[1])
@

\subsubsection{Apply}
This saves us a bit of time because it simplifies what we have to type, but it's still not very efficient. If we wanted to speed up the process even further, we could use R's \texttt{apply()} functions to automatically perform the function on every element in our \texttt{temps} vector.

<<temp3>>=

<<temp2,echo=false>>
celsius <- sapply(temps,FUN=ftoc)
celsius
@
We can also use \texttt{apply()} built-in functions to matrices, vectors, and data.frames. This can be helpful if you want to calculate summary statistics for a number of different subgroups of observations within your dataset. Apply can also be used to do a lot of other things (including some cool and interesting things), but I won't go into the details here.

\subsection{Loops}
The last important piece of R programming that you should know about is looping. Like \texttt{apply()}, loops allow you to perform an otherwise tedious task a number of times on the same or different data, similar to using \texttt{apply()}. Loops and \texttt{apply()} are what really sets R apart from its competitors like SPSS, SAS, and Stata. There are several different types of loops that can be used, which are describe in detail at \url{http://cran.r-project.org/doc/manuals/R-lang.html#Looping}. The simplest loop can be used to perform the same temperature conversion we used above.

<<temp4>>=

<<temp3,echo=false>>
celsius <- numeric(length(temps))
for (i in 1:length(temps)) {
	celsius[i] <- ((temps[i]-35)*5)/9
}
celsius
@
Here, we tell R that we want to conduct a task for $i$ number of times, specified by 1 to the length of our \texttt{temps} vector. For each iteration of the loop, we take the $i^{th}$ element of the \texttt{temps} vector, perform the temperature conversion calculation and store the resulting value in the $i^{th}$ element of the \texttt{celsius} vector. When the loop completes, R displays nothing, so we have to call the \texttt{celsius} vector. If we didn't need to store each converted value, we could also use the \texttt{print()} command to simply display the resulting calculations like so:

<<temp5>>=

<<temp4,echo=false>>
for (i in 1:length(temps)) {
	print(((temps[i]-35)*5)/9)
}
@
The \texttt{print()} function will be helpful if you run very large or complicated loops.

But now we've seen multiple ways to apply functions to objects. Which should we use in which situation? Given that we have nearly unlimited computing power and time, the distinctions between these methods are fairly small. \texttt{apply()} functions tend to be faster than loops, but that only matters if the task you're performing is very complicated. Loops are more versatile because you can perform multiple tasks within a single iteration of a loop, as well as nest loops inside one another. For example, if you needed to perform a task on each element of an $i$-by-$j$ matrix, you could nest a loop indexed by $j$ within a loop indexed by $i$, or vice versa. The final choice of how to program depends on the needs of the particular task you're aiming to complete. Often there many, many ways to accomplish the same task, which makes R uniquely versatile among statistical packages.

\section{Conclusion}\label{sec:conclusion}
So now you've learned the basic information you need to know to use R for this class. Hopefully this tutorial has helped you be less intimidated by and frustrated with the language and this course as a whole. Best of luck and let me know if you have questions!

\end{document}
